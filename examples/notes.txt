################
Part 1: INTRO
################

Last year:
- We demonstrated a header-only debug methodology that included
  custom debug triggers and internal buffering. Component Debug Probe
- Scott demonstrated a built-in interactive console that interacts
  with internal data via an internal 'object map'.

Today:
- We'll demonstrate the latest work to converge both approaches

Main goals:
- Explore interactive console's main features in a 'real world' model
- Demonstrate using partial checkpointing for parameter sweeps and more

Since we last met
- Major lift on serialization and checkpointing, functional/performance testing
- Bringing up foundational which builds on and benefits from the serialization work.

Challenge for general purpose debugger: 'eating your own dog food'.

The Model under Test (MUT):

A Real design:
- Structurally complex, unique components, subcomponents, and links.
- Utilize external libraries
- Hierarchal Class design

Priming the model for debug:
- Add the serialization framework but do not populate it.
- We just want minimal coding to enable debug.
- Very far from caring much about checkpointing.

#####################
Part 2: Debug Intro
#####################
cd examples/debug_intro

The debugger
- Enter the console. Discuss command-line
- Just focus on a bit of code where to observe/control some variables
- Review commands via help, detailed help
- History (!!...)
- Auto-completion

Simple debug: watch
- Run to completion and note the bad completion result
- Reenter console. set logging on
- Navigate to loss/optimizer, show vars
- help watch
- Set a watch on current_learning_rate_ changing, run/print  - note AC
- set watch for <var> changed && <var> < 0.000099
- run; printTrace; discuss

Simple debug: trace
- edit the log file and replay to get to the optimizer
- clear watchlist
  help trace
  trace iterations_ >= 5 && iterations_ < 10 : 32 16 : current_learning_rate_ : interactive
  help printtrace
  watchlist
- run, prt, discuss trace
- rerun and use sethandler
  help sethandler
  sethandler 0 bc

Modify the simulation
- Say we've debugged and concluded our learning rate is too slow
- print the learning_rate_, set to 0.001 (beware of bug!)
- print to confirm
- run, show good result
... so this suggests we can do parameter sweeps. No checkpoint needed.

- Show the parameter sweep code and run it

Discussion
   - We don't need to be checkpointable to use the debugger
   - other application: error injection

###########################################
Part 3: A Synchronous Checkpoint for Debug
###########################################

cd examples/sync_checkpoint

Intro
- We can use a watchpoint trigger to create a checkpoint but....
- With multiple threads we can only do this at a synchronization point
n- Built in support to pause the state machine for synchronization purposes
  

Refer to block diagram and describe state machine.
Open gen-checkpoint.in and enter commands manually

Alternatively, we could just use a `set var action`
Open gen-checkpoint2.in and use replay in iconsole

######################################################
Part 4: Running Predictions Using a Checkpointed Model
######################################################
cd examples/restart

- We need to finish the job of serialization.
- This is surprisingly little code: the controller, and the layer weights/biases.
- Refer to doc - Dense Layer is the interesting one

Now we simply will restart SST from a checkpoint and
enter the interactive console to provide a new
image path and clear the pause bit.

open restart.in and review

open the images for a visual

And for the GRAND FINALE!

./gen-checkpoint2.sh
sst nn.py --interactive-start=0 --load-checkpoint checkpoint/checkpoint_1_32262251000/checkpoint_1_32262251000.sstcpt
> replay restart.in

Discussion
